{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3cf9ff9-3a46-4229-b1b4-2cdda9cc0b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sbi \n",
    "\n",
    "import lal as _lal\n",
    "from pycbc.waveform import get_fd_waveform\n",
    "from pycbc.psd import aLIGOZeroDetHighPower\n",
    "from pycbc.filter import highpass\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from sbi import analysis as analysis\n",
    "from sbi.analysis import pairplot\n",
    "from sbi.inference import NPE, simulate_for_sbi\n",
    "from sbi.utils import BoxUniform \n",
    "from sbi.utils.user_input_checks import (\n",
    "    check_sbi_inputs,\n",
    "    process_prior,\n",
    "    process_simulator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6078bca3-35a4-4037-81a8-8f5cd2e893e2",
   "metadata": {},
   "source": [
    "#### (chatGPT) The noise:\n",
    "\n",
    "detectore noise is given by:\n",
    "\n",
    "$$n(f) - \\mathbb{C} N(0,0.5S_n(f))$$\n",
    "\n",
    "where $S_n(f)$ is the one-sided power spectral density at frequency f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "607b9583-4e9c-431b-acf3-834492686679",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "theta[0]: mass1 (solar masses)\n",
    "theta[1]: mass2 (solar masses)\n",
    "theta[2]: distance (Mpc)\n",
    "\"\"\"\n",
    "\n",
    "def simulator(theta):\n",
    "    delta_f = 1/16\n",
    "    f_lower = 20\n",
    "    f_final = 512\n",
    "    num_sim = theta.shape[0]\n",
    "    num_freq = int(((f_final - f_lower) / delta_f) + 1)\n",
    "    h_freq = np.zeros(shape = (num_sim, 4, num_freq))\n",
    "\n",
    "    # Calculate the gravitational wave strains in frequency space num_sim times\n",
    "    for i in range(num_sim):\n",
    "        mass1 = theta[i,0]\n",
    "        mass2 = theta[i,1]\n",
    "        distance = 10 ** theta[i,2]\n",
    "\n",
    "        \n",
    "        hp, hc = get_fd_waveform(approximant=\"TaylorF2\",\n",
    "                                 mass1=mass1,\n",
    "                                 mass2=mass2,\n",
    "                                 delta_f=delta_f,\n",
    "                                 f_lower=f_lower,\n",
    "                                 f_final=f_final,\n",
    "                                 distance=distance,\n",
    "                                 inclination=0.0,\n",
    "                                 coa_phase=0.0)\n",
    "        \n",
    "        hp_freq = hp.to_frequencyseries()\n",
    "        frequencies = hp_freq.sample_frequencies.numpy()\n",
    "        hp_amplitudes = hp_freq.numpy()[frequencies >= f_lower]\n",
    "        hp_amplitudes_real = np.real(hp_amplitudes)\n",
    "        hp_amplitudes_imaginary = np.imag(hp_amplitudes)\n",
    "        \n",
    "        hc_freq = hc.to_frequencyseries()\n",
    "        hc_amplitudes = hc_freq.numpy()[frequencies >= f_lower]\n",
    "        hc_amplitudes_real = np.real(hc_amplitudes)\n",
    "        hc_amplitudes_imaginary = np.imag(hc_amplitudes)\n",
    "        \n",
    "        h_freq[i,0,:] = hp_amplitudes_real\n",
    "        h_freq[i,1,:] = hp_amplitudes_imaginary\n",
    "        h_freq[i,2,:] = hc_amplitudes_real\n",
    "        h_freq[i,3,:] = hc_amplitudes_imaginary\n",
    "        \n",
    "        hp_psd = aLIGOZeroDetHighPower(length = len(frequencies), delta_f = delta_f, low_freq_cutoff = f_lower).numpy()[frequencies >= f_lower]\n",
    "        hp_scale = np.sqrt(0.5 * hp_psd * delta_f)\n",
    "        hp_noise_real = np.random.normal(0, hp_scale)\n",
    "        hp_noise_imaginary = np.random.normal(0, hp_scale)\n",
    "        \n",
    "        hc_psd = aLIGOZeroDetHighPower(length = len(frequencies), delta_f = delta_f, low_freq_cutoff = f_lower).numpy()[frequencies >= f_lower]\n",
    "        hc_scale = np.sqrt(0.5 * hc_psd * delta_f)\n",
    "        hc_noise_real = np.random.normal(0, hc_scale)\n",
    "        hc_noise_imaginary = np.random.normal(0, hc_scale)\n",
    "        \n",
    "        h_freq[i,0,:] += hp_noise_real\n",
    "        h_freq[i,1,:] += hp_noise_imaginary\n",
    "        h_freq[i,2,:] += hc_noise_real\n",
    "        h_freq[i,3,:] += hc_noise_imaginary\n",
    "\n",
    "    h_freq = h_freq.reshape(h_freq.shape[0],-1)\n",
    "\n",
    "    h_freq = torch.tensor(h_freq, dtype=torch.float32)\n",
    "    return h_freq\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e4a11b3-8c6c-4fcc-9959-4a44d8f3d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass1 = 1\n",
    "mass2 = 2\n",
    "distance = 500\n",
    "delta_f = 1/16\n",
    "f_lower = 20.0\n",
    "f_final = 512.0\n",
    "\n",
    "hp, hc = get_fd_waveform(approximant=\"TaylorF2\",\n",
    "                             mass1=mass1,\n",
    "                             mass2=mass2,\n",
    "                             delta_f=delta_f,\n",
    "                             f_lower=f_lower,\n",
    "                             f_final=f_final,\n",
    "                             distance=distance,\n",
    "                             inclination=0.0,\n",
    "                             coa_phase=0.0)\n",
    "\n",
    "ht = hp.to_timeseries()\n",
    "times = ht.sample_times.numpy()\n",
    "amplitude = ht.numpy()\n",
    "\n",
    "plt.plot(times, amplitude)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain h(t)\")\n",
    "plt.savefig(\"time series\")\n",
    "plt.close()\n",
    "\n",
    "hp_freq = hp.to_frequencyseries()\n",
    "frequencies = hp_freq.sample_frequencies.numpy()\n",
    "hp_amplitudes = hp_freq.numpy()\n",
    "hp_amplitudes_real = np.real(hp_amplitudes)\n",
    "hp_amplitudes_imaginary = np.imag(hp_amplitudes)\n",
    "\n",
    "hc_freq = hc.to_frequencyseries()\n",
    "hc_amplitudes = hc_freq.numpy()\n",
    "hc_amplitudes_real = np.real(hc_amplitudes)\n",
    "hc_amplitudes_imaginary = np.imag(hc_amplitudes)\n",
    "\n",
    "h_freq = np.zeros(shape = (4, len(frequencies)))\n",
    "h_freq[0,:] = hp_amplitudes_real\n",
    "h_freq[1,:] = hp_amplitudes_imaginary\n",
    "h_freq[2,:] = hc_amplitudes_real\n",
    "h_freq[3,:] = hc_amplitudes_imaginary\n",
    "\n",
    "hp_psd = aLIGOZeroDetHighPower(length = len(frequencies), delta_f = delta_f, low_freq_cutoff = f_lower)\n",
    "hp_scale = np.sqrt(0.5 * hp_psd.numpy() * delta_f)\n",
    "hp_noise_real = np.random.normal(0, hp_scale)\n",
    "hp_noise_imaginary = np.random.normal(0, hp_scale)\n",
    "\n",
    "hc_psd = aLIGOZeroDetHighPower(length = len(frequencies), delta_f = delta_f, low_freq_cutoff = f_lower)\n",
    "hc_scale = np.sqrt(0.5 * hc_psd.numpy() * delta_f)\n",
    "hc_noise_real = np.random.normal(0, hc_scale)\n",
    "hc_noise_imaginary = np.random.normal(0, hc_scale)\n",
    "\n",
    "h_freq[0,:] += hp_noise_real\n",
    "h_freq[1,:] += hp_noise_imaginary\n",
    "h_freq[2,:] += hc_noise_real\n",
    "h_freq[3,:] += hc_noise_imaginary\n",
    "\n",
    "plt.plot(frequencies, h_freq[0,:])\n",
    "plt.plot(frequencies, h_freq[1,:])\n",
    "plt.xlabel('frequency (Hz)')\n",
    "plt.ylabel('Strain amplitude h(f)')\n",
    "plt.savefig(\"frequency series hp + noise\")\n",
    "plt.close()\n",
    "\n",
    "plt.plot(frequencies, h_freq[2,:])\n",
    "plt.plot(frequencies, h_freq[3,:])\n",
    "plt.xlabel('frequency (Hz)')\n",
    "plt.ylabel('Strain amplitude h(f)')\n",
    "plt.savefig(\"frequency series hc + noise\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c14863cb-0a30-4e88-b732-965df93b13f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.array([[30,30,np.log10(100)],\n",
    "                 [40,15,np.log10(200)],\n",
    "                 [50,25,np.log10(300)],\n",
    "                 [20,40,np.log10(400)],\n",
    "                 [35,20,np.log10(500)],])\n",
    "h_freq = simulator(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1df6baa3-b643-4a5a-a502-a9e5a2baaae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 31492])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e32b747-0c17-4d9f-a254-1d4bdb100fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9756c8c2c294a21a3430fd5e240f30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 35 epochs."
     ]
    }
   ],
   "source": [
    "delta_f = 1/16\n",
    "f_lower = 20\n",
    "f_final = 512\n",
    "num_sim = 20000\n",
    "\n",
    "# sim_wrapper = lambda theta: simulator(theta, delta_f = delta_f, f_lower = f_lower, f_final = f_final)\n",
    "# def sim_wrapper(theta):\n",
    "#     return simulator(theta = theta, delta_f = delta_f, f_lower = f_lower, f_final = f_final)\n",
    "\n",
    "m_lowerbound = 5\n",
    "m_upperbound = 10\n",
    "log_dinstance_lowerbound = np.log10(100)\n",
    "log_distance_upperbound = np.log10(300)\n",
    "\n",
    "prior = BoxUniform(low=torch.tensor([m_lowerbound, m_lowerbound, log_dinstance_lowerbound]), \n",
    "                   high=torch.tensor([m_upperbound, m_upperbound, log_distance_upperbound]))\n",
    "\n",
    "# Check prior, simulator, consistency\n",
    "prior, num_parameters, prior_returns_numpy = process_prior(prior)\n",
    "simulator = process_simulator(simulator, prior, prior_returns_numpy)\n",
    "check_sbi_inputs(simulator, prior)\n",
    "\n",
    "# Create inference object. Here, NPE is used.\n",
    "inference = NPE(prior=prior, density_estimator=\"zuko_maf\")\n",
    "\n",
    "#generate simulations and pass to the inference object\n",
    "theta, h_freq = simulate_for_sbi(simulator, proposal=prior, num_simulations=num_sim)\n",
    "inference = inference.append_simulations(theta, h_freq)\n",
    "\n",
    "# train the density estimator and build the posterior\n",
    "density_estimator = inference.train()\n",
    "posterior = inference.build_posterior(density_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e54e7326-d164-4498-9081-b6e5a897e8dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The trailing dimensions of `theta_or_x` do not match the `event_shape`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# generate our observation\u001b[39;00m\n\u001b[1;32m      3\u001b[0m h_obs \u001b[38;5;241m=\u001b[39m simulator(theta_true)\n\u001b[0;32m----> 5\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_posterior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh_obs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m _ \u001b[38;5;241m=\u001b[39m analysis\u001b[38;5;241m.\u001b[39mpairplot(\n\u001b[1;32m      8\u001b[0m     samples, \n\u001b[1;32m      9\u001b[0m     limits\u001b[38;5;241m=\u001b[39m[[m_lowerbound, m_upperbound], \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     points\u001b[38;5;241m=\u001b[39mtheta_true \u001b[38;5;66;03m# add ground truth thetas,\u001b[39;00m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGravitational Wave Posterior\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sbi/inference/posteriors/direct_posterior.py:109\u001b[0m, in \u001b[0;36mDirectPosterior.sample\u001b[0;34m(self, sample_shape, x, max_sampling_batch_size, sample_with, show_progress_bars)\u001b[0m\n\u001b[1;32m    107\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize(sample_shape)\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m    108\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x_else_default_x(x)\n\u001b[0;32m--> 109\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mreshape_to_batch_event\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcondition_shape\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.sample() supports only `batchsize == 1`. If you intend \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto sample multiple observations, use `.sample_batched()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvariant embedding net.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sbi/neural_nets/estimators/shape_handling.py:74\u001b[0m, in \u001b[0;36mreshape_to_batch_event\u001b[0;34m(theta_or_x, event_shape)\u001b[0m\n\u001b[1;32m     72\u001b[0m trailing_theta_or_x_shape \u001b[38;5;241m=\u001b[39m theta_or_x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39mevent_shape_dim:]\n\u001b[1;32m     73\u001b[0m leading_theta_or_x_shape \u001b[38;5;241m=\u001b[39m theta_or_x\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39mevent_shape_dim]\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m trailing_theta_or_x_shape \u001b[38;5;241m==\u001b[39m event_shape, (\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe trailing dimensions of `theta_or_x` do not match the `event_shape`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(leading_theta_or_x_shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# A single datapoint is passed. Add batch artificially.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m theta_or_x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: The trailing dimensions of `theta_or_x` do not match the `event_shape`."
     ]
    }
   ],
   "source": [
    "theta_true = prior.sample((1,))\n",
    "# generate our observation\n",
    "h_obs = simulator(theta_true)\n",
    "\n",
    "samples = loaded_posterior.sample((10000,), x=h_obs)\n",
    "\n",
    "_ = analysis.pairplot(\n",
    "    samples, \n",
    "    limits=[[m_lowerbound, m_upperbound], \n",
    "            [m_lowerbound, m_upperbound], \n",
    "            [log_dinstance_lowerbound, log_distance_upperbound]],\n",
    "    figsize=(8, 8),\n",
    "    labels=[r\"$m_1$\", r\"$m_2$\", r\"$d$\"],\n",
    "    points=theta_true # add ground truth thetas,\n",
    ")\n",
    "\n",
    "plt.savefig(\"Gravitational Wave Posterior\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00f6080e-fef4-4b36-aa54-56a185e3769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(posterior, 'posterior.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e853ed61-79b7-479d-95f3-106487cea926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch-local/scur2965.11859728/ipykernel_3426891/3268222305.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_posterior = torch.load('posterior.pt')\n"
     ]
    }
   ],
   "source": [
    "loaded_posterior = torch.load('posterior.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463dce4f-42cc-47f7-93c1-d6db8b96d8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c373233-e62f-41c0-8fcb-c753e03a7f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0255eb-20fe-45a7-84dd-59beff087b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
